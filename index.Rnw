\documentclass[APA,LATO1COL]{WileyNJD-v2}
% \usepackage{natbib}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{bm}
\usepackage{multirow}
\usepackage{hyperref}
%\usepackage{endfloat} % Figures to the end of the document

\usepackage{anyfontsize}% remove font warnings
\usepackage{subcaption}  % an alternative package for sub figures
%\renewcommand{\subfloat}[2][need a sub-caption]{\subcaptionbox{\normalsize #1}{#2}}
% --- Editing ------------------------------------------------------------------

\newcommand{\hh}[1]{{\textcolor{orange}{#1}}}
\newcommand{\svp}[1]{{\textcolor{magenta}{#1}}}
\newcommand{\dc}[1]{{\textcolor{teal}{#1}}}

% ------------------------------------------------------------------------------

\graphicspath{{figure/}}

\articletype{Article Type}%

\received{26 April 2016}
\revised{6 June 2016}
\accepted{6 June 2016}

\raggedbottom

\setlength\parindent{0pt} % noindent for the whole document

\begin{document}
% \tableofcontents
\title{Statistical Significance Calculations for Scenarios in Visual Inference\protect\thanks{This is an example for title footnote.}}

\author[1]{Susan VanderPlas*}

\author[2]{Christian R\"ottger}

\author[3]{Dianne Cook}

\author[4]{Heike Hofmann}

\authormark{VanderPlas \textsc{et al}}


\address[1]{\orgdiv{Department of Statistics}, \orgname{University of Nebraska-Lincoln}, \orgaddress{\state{Nebraska}, \country{United States}}}

\address[2]{\orgdiv{Department of Mathematics}, \orgname{Iowa State University}, \orgaddress{\state{Iowa}, \country{United States}}}

\address[3]{\orgdiv{Department of Econometrics and Business Statistics}, \orgname{Monash University}, \orgaddress{\state{Victoria}, \country{Australia}}}

\address[4]{\orgdiv{Department of Statistics}, \orgname{Iowa State University}, \orgaddress{\state{Iowa}, \country{United States}}}

\corres{*Susan VanderPlas, This is sample corresponding address. \email{authorone@gmail.com}}

\presentaddress{This is sample for present address text this is sample for present address text}

\abstract[Summary]{\dc{Statistical inference provides the protocols for conducting rigorous science, but data plots provide the opportunity to discover the unexpected. These disparate endeavours are bridged by visual inference, where a lineup protocol can be employed for statistical testing. Human observers are needed to to read the lineups, typically using a crowd-sourcing service.  This paper describes a new approach for computing statistical significance associated with the results from applying a lineup protocol. It utilises a Dirichlet distribution to recognise that some plots, even though they are null plots, will attract more attention from the visual evaluator than others. The procedures make statistical inference possible for a broader range of data problems.}
}

\keywords{data visualization, statistical graphics, hypothesis testing, data science}

\maketitle

%\footnotetext{\textbf{Abbreviations:} ML, maximum likelihood;}


<<setup, echo = F, include = F>>=
library(tidyverse)
library(mgcv)
library(Cairo)
knitr::opts_chunk$set(echo = F, message = F, warning = F, dev = "CairoPDF")
theme_set(theme_bw())
@

<<code, include = F>>=
source("code/functions.R")
@

\section{Introduction}

% ---- Gentle introduction/ power of graphics ----------------------------------
Graphics provide the opportunity to understand statistical data at an intuitive level: 
 we can gain more information  by looking at a scatter plot than what summary statistics tell us, especially when the data departs from normality~\citep{anscombe:1972,matejka:2017}.
 \svp{XXX This feels a bit too abrupt for the first sentence... XXX}

% ---- Graphics and hypothesis testing -----------------------------------------
Statistical graphics allow us to leverage the bandwidth of the visual system for implicit data analysis. Because this analysis is implicit, we often assume these visual analyses are not decisive in the same way that a hypothesis test is decisive.
Graphics generally do not come with a significance threshold, and in many cases we do not explicitly declare the hypothesis we might be testing before viewing the data plot.%\svp{XXX this is more general than lineups: we haven't introduced lineups yet, so we are talking about more generic charts.}
\svp{\citet{buja:2009} introduced a protocol for \emph{visual inference} that allows for formal hypothesis testing using graphical displays and visual evaluation.}

In order to test whether a chart shows a visually significant result, we can use the same machinery used by randomization tests: 
(1) construct a method to generate data consistent with the null hypothesis, such as using randomization or drawing samples from a model consistent with the null hypothesis, (2) generate many copies of the test statistic (in this case, the plot), and (3) see where the observed statistic falls in the distribution of artificially generated quantities.
The conceptual framework was described in \citet{buja:2009}, who introduced two protocols: \svp{a lineup, and a Rorschach (or null) lineup.}

An assembly of several null plots with a target (or data) plot is called a \emph{lineup}, \hh{named} after the \hh{law-enforcement} procedure to line up a  suspect among a set of innocents  to check if a victim can identify the suspect as the perpetrator of the crime. 
\hh{In its visual version, } lineups are typically composed of $m-1$ ``null" plots (generated under the null hypothesis) and one data plot containing the \dc{observed} data. \svp{XXX sometimes, data generated from an alternate model and not necessarily real data...?} 
% 
\svp{The Rorschach lineup is named after the ink-blot test\citep{exner2003rorschach} historically used in psychoanalysis; as in the inkblot test, the Rorschach lineup provides ambiguous visual signals that are open to interpretation.}
Figure \ref{fig:typesoflineups} \svp{shows several examples of each type of lineup.}
In a Rorschach \svp{lineup}, all plots are null plots; the purpose is to assess the extent of visual variation that occurs in data generated by the null mechanism.

%\hh{This lineup is also called a  one target lineup; two-target lineups have been introduced in  \citet{vanderplas:2017}. Two-target lineups} can be used to test the visual salience of two competing effects. Technically, \hh{this makes} the Rorschach \hh{protocol a zero-target} lineup.

% ---- Graphs as statistics ----------------------------------------------------
\svp{The fundamental premise of visual inference is that charts are visual statistics: summaries of data sets generated by mathematical functions.}
\svp{Underlying this premise is the concept of a}
% Visual inference builds from considering data plots to be visual statistics: charts are \hh{rendered}, after all, from \hh{quantities based on values} in a \svp{data set}.
% \dc{Lineups provide inferential machinery for data plots. To make this possible the plot needs to be considered to be a statistic, a functional mapping of the variables into a summary.
% This is possible following the
\dc{grammar of graphics initially laid out by \citet{wilkinson:1999}, and further developed in \citet{hadley:2009}, that provides a functional mapping from variables (abstractly defined) into graphical elements of a plot.
This abstract plot definition} \svp{allows us to declare a hypothesis XXX model? not quite to hypothesis stage yet with a single plot? XXX by specifying the relationship between the variables and the spatial elements of the plot.}
% to come from under the rug (implicit), be explicitly declared.
For example, the scatterplots shown in the one target lineups in Figure \ref{fig:typesoflineups}b \svp{map} variable 1 to the $x$ axis and variable 2 to the $y$ axis, with the intent to study association between the two variables.

% ---- Lineups as tests --------------------------------------------------------
\svp{If charts are visual statistics, then it is only natural to consider using these visual statistics to conduct hypothesis tests.}
\svp{In the scatterplot example above,} the null hypothesis is that there is no association between the two variables and the \svp{corresponding} alternative \svp{hypothesis is} that there is association.
\svp{Conducting a test using the observed data plot requires that we compare the data plot to a reference distribution.} % XXX rephrased for consistent mood (subjunctive/declarative) relative to the previous few lines.
% To conduct a test, using the observed data plot, requires a comparison with its sampling distribution.
\svp{Any null generating mechanism, such as randomization or sampling from a known distribution, may be used to generate the data for the null panels in the lineup.}
% A null generating mechanism can be used to make draws from the sampling distribution, resulting in null plots.

\svp{In a numerical statistical test, the summary statistics are naturally ordered, and the test statistic is compared to quantities consistent with the null hypothesis; often, a p-value is used to assess the probability that the observed statistic would arise by chance under the null hypothesis.}
\svp{When conducting visual inference, the statistics have no such natural ordering; instead, our statistics must be evaluated by human participants.}
Typically, graphical tests utilize a service like Amazon Mechanical Turk~\citep{turk} to acquire \svp{evaluations of lineups.} % Better to not specify which scenario we're typically operating under just yet.
%multiple evaluations of the same lineup.
%\footnote{Cite Giora's Deep Learning work, \url{http://giorasimchoni.com/deep_visual_inference.html}})
\svp{An extreme visual test statistic is one which is easily distinguishable from other null plots in the lineup; that is, if the data panel is identified when the lineup is evaluated, we would reject the null hypothesis.}
\svp{Thus, lineups have the features of a \emph{statistical test}.}
\svp{One notable difference between visual and numerical statistical tests is that visual tests are more XXX comprehensive? XXX: individuals are asked to select one or more plots from the lineup which are ``different", but typically, the specific type of difference is left unspecified.}
\svp{As a result, a visual test might evaluate several simultaneous characteristics of a plot, where the equivalent numerical assessment may involve multiple tests using different test statistics.}
\svp{Occasionally, because there is some inductive reasoning required of the participant, the feature used to select the ``different" panel is not the feature under investigation by the experimenter.}

\svp{Typically, lineups consist of $m = 20$ panels, $m_0 = 19$ of which are generated from the null distribution.
Under this formulation, a single evaluation of a lineup in which the data panel is selected would have a visual p-value of $p\leq 0.05$.}
\svp{In most visual inference experiments, each lineup is evaluated by multiple individuals, and the aggregated results are used to generate a visual p-value using the method described in \citet{majumder2013validation}.}
\dc{This approach is simple, and a reasonably good approximation for assessing the significance of structure in a plot, but it fails to account for} \svp{variations in the design of visual inference experiments with multiple observers.}

% svp: not sure if you want to introduce P(C >= c_t) here, or later.

In this paper, we propose a \dc{new approach for computing $p$-values} using a Dirichlet-multinomial distribution to model the probabilities of selecting each panel \svp{and the} observed participant selections.
% This framework for analysis of visual inference data has been in use as part of the \texttt{vinference} package~\citep{vinference} \citep{loyAreYouNormal2015,loy2016variations,vanderplas:2017}, but has not been formally described in any publication.
\svp{This model is more flexible than the binomial model used in \citet{majumder2013validation}, and better represents the perceptual and statistical dependencies present when lineups are evaluated by multiple people.}
\svp{Leveraging this model, we propose a method for estimation of the model parameters and present a diagnostic procedure for null plot generation models.}

<<typesoflineups, eval = T,echo=FALSE, out.width='\\textwidth', fig.width=12, fig.height=6, fig.cap = "Types of lineups. In a Rorschach, all plots are null plots, with a purpose of understanding patterns that may occur by chance. A one target lineup has one data plot, and the remaining are null plots.">>=
library(nullabor)
library(gridExtra)
set.seed(2020)
df <- tibble(x=runif(100)) %>%
  mutate(y1 = -4*(x-0.5) + rnorm(100)) %>%
  mutate(y2 = ifelse(x<0.5, (x-0.5) + 5 + rnorm(100),
                     (x-0.5) - 5 + rnorm(100)))
p1 <- ggplot(rorschach(null_permute('y1'), df, n=5), aes(x, y1)) +
  geom_point() +
  facet_wrap(~ .sample, ncol=5) +
  theme(aspect.ratio=1,
        axis.ticks = element_blank(),
        axis.text = element_blank()) +
  xlab("") + ylab("") +
  ggtitle("a. Rorschach")
p2 <- ggplot(lineup(null_permute('y1'), df, n=5), aes(x, y1)) +
  geom_point() +
  facet_wrap(~ .sample, ncol=5) +
  theme(aspect.ratio=1,
        axis.ticks = element_blank(),
        axis.text = element_blank()) +
  xlab("") + ylab("") +
  ggtitle("b. One target lineup")
grid.arrange(p1, p2, ncol=1)
@

\subsection{Modeling Lineup Panel Selections}\label{sec:alpha}

% ---- Make the argument for dirichlet distribution based on the task structure:
% modeling of proportions/selection probs which sum to 1. ----------------------
\svp{
The lineup evaluation task boils down to a selection of one of $m$ panels in a lineup. 
We model the probability of selecting panel $i$ as $\theta_i, i = 1, ..., m$, where $\bm\theta \sim Dirichlet(\bm\alpha)$. 
The $m$-dimensional Dirichlet distribution generates $\bm\theta$ distributed on the $m-1$ simplex, that is, $\sum \theta_i = 1$. 
When $\alpha_1 = \alpha_2 = ... = \alpha_m$, the distribution is a symmetric Dirichlet distribution. 
Such a simplification might be used in a Rorschach lineup, where all of the $m$ panels are generated using the same mechanism.
}

% Stolen from heike/lineup-scenarios
When $\alpha = 1$, the symmetric Dirichlet distribution is uniform on the $m-1$ dimensional simplex.
When $\alpha < 1$, the mass of the distribution is along the edges of the simplex, where most values of $\theta_i$ will be close to 0. When $\alpha>1$, the mass of the distribution is in the center of the simplex, with most of the $\theta_i$ having similar values.
\autoref{fig:simplex} shows ternary plots~\citep{ggtern} of values simulated from a 3-dimensional Dirichlet distribution which illustrate the effect of $\alpha$ on the sampled $\bm\theta$.

<<simplex, eval = F,echo=FALSE, out.width='\\textwidth', fig.width=12, fig.height=4, fig.cap = "Dirichlet distributed samples on the 2-dimensional simplex.">>=
simplex <- purrr::map_df(.x = c(1/3, 1, 3), ~data.frame(
  gtools::rdirichlet(5000, alpha = rep(.x, 3))
), .id = "alpha") %>%
  rename(p1 = X1, p2 = X2, p3 = X3) %>%
  mutate(alphalabel = factor(alpha, levels = 1:3, labels = c("alpha: 1/3", "alpha: 1", "alpha: 3")))

ggtern::ggtern(aes(x = p1, y = p2, z = p3), data = simplex) +
  geom_point(alpha = .075, shape = 16) +
  facet_wrap(~alphalabel, labeller = "label_parsed") +
  theme(panel.background = element_rect(colour = "black"))
@

\begin{figure}
\includegraphics[width=\textwidth]{figure/simplex-1.pdf}
\caption{Dirichlet distributed samples on the 2-dimensional simplex. $\alpha = 1$ is a uniform distribution on the simplex, $\alpha < 1$ up-weighs the (hyper)faces of the simplex, $\alpha > 1$ puts more weight towards the center of the simplex.\label{fig:simplex}}
\end{figure}

%Marginal Beta($\alpha, 2\alpha$) densities corresponding to \\autoref{fig:simplex}.
<<betas, echo=FALSE, out.width='\\textwidth', fig.width=12, fig.height=4, fig.cap="Marginal Beta($\\alpha, 2\\alpha$) densities corresponding to the above Dirichlet densities.">>=
p <- seq(0,1, by=0.005)
alpha <- c(1/3,1,3)
betas <- data.frame(expand.grid(p=p, alpha=alpha))
betas$density <- with(betas, dbeta(p, alpha, 2*alpha))
betas$density[is.infinite(betas$density)] <- 0
betas <- rbind(betas, data.frame(p=0,alpha=1,density=0))
betas$alphalabel <- factor(betas$alpha)
levels(betas$alphalabel) <- expression("alpha: 1/3", "alpha: 1", "alpha: 3")
ggplot(data=betas, aes(x=p, y=density)) +
  geom_polygon(fill=I("grey50"), alpha=I(.8), colour=I("grey20")) +
  ylab("density") + facet_wrap(~alphalabel, labeller="label_parsed") +
  ggplot2::theme_bw()
@

% End stolen from heike/lineup-scenarios

% \svp{By utilizing a Dirichlet$(\bm\alpha)$ distribution to model the panel selection probability vector $\bm\theta$, we build into the model the acknowledgement that not all randomly generated plots are of equal visual interest, and thus, not all selection probabilities $\theta_i$ are equal.
% }

% \svp{Perceptually, the mixture model proposed in this paper mimics the tendency for us to focus in on a handful of the available panels of a lineup.
% By allowing $\theta$ to vary, we are building into our model the acknowledgement that not all randomly generated plots are equally visually ``interesting"; the less interesting plots tend to not receive equal amounts of attention during the lineup evaluation process.}
% \svp{XXX can we cite that eye tracking study here? Does it back up that claim? XXX} \hh{XXX we've seen that phenomenon over and over again. but, yes, the eye-tracker study shows it, too.} \svp{XXX I know we've seen it over and over, but I'm hoping to provide some sort of concrete evidence as far as a citation might go... just backing up an otherwise unsubstantiated claim.}
While graphical illustrations of the $m$-dimensional dirichlet distribution are more difficult \svp{when $m>3$}, we can use simulation to assess the meaning of $\alpha$ as it relates to lineup panel selection probabilities $\theta_i$. \autoref{fig:prior-predictive} shows simulated selection probabilities $\theta_i$, sorted such that the panel with the highest selection probability is first,  for several values of $\alpha$ \svp{in a $m=20$ panel lineup}.
It is evident that for $\alpha<0.05$ only one panel of the lineup receives significant attention, while for $\alpha> .25$, participant attention is divided among several interesting panels of the lineup.

<<prior-predictive, echo = F, fig.cap = "Simulation of the panel selection probabilities $\\theta_i$, sorted, for different values of $\\alpha$ (left). In the right column, panel selection probabilities estimated from lineups used in past visual inference experiments; these probabilities are calculated from lineups with finite evaluations, so the calculated probabilities are not continuous. For low values of $\\alpha$, plot selections are concentrated on only a few plots, while higher values of $\\alpha$ show a wider spread of selections among more plots. The included selection probabilities from previous studies show that not all panels in each lineup are selected, even when evaluated multiple times; it is also clear that the selection probabilities are more concentrated in the turk4 study, where in some lineups only one panel was selected; in the turk14 study, at least 4 panels were selected in every lineup.", fig.width = 8, fig.height = 6, out.width = "\\textwidth" >>=
# set.seed(5019230943) # HH: too large for my machine
set.seed(519223094)

alphas <- c(.001, .02, .05, .1, .5, 1, 2, 5, 20)
# Simulate for different values of alpha
prior_sim <- tibble(alpha = alphas,
                     sel_prob = purrr::map(alpha,~ gtools::rdirichlet(100, rep(., 19)))) %>%
  mutate(
    sel_prob_ord = purrr::map(sel_prob, ~apply(., 1, sort, decreasing = T)),
    sel_prob_long = purrr::map(
      sel_prob_ord,
      ~tibble(idx = rep(1:nrow(.x), times = ncol(.x)),
              rep = rep(1:ncol(.x), each = nrow(.x)),
              prob = as.vector(.x, mode = "numeric")))
  ) %>%
  select(-sel_prob, -sel_prob_ord) %>%
  unnest(cols = c(sel_prob_long)) %>%
  arrange(alpha) %>%
  mutate(label = sprintf("alpha == %f", alpha) %>% factor(levels = sprintf("alpha == %f", alphas), ordered = T))

# Calculate thetas for different turk studies
studies_sum <- readr::read_csv("data/all-turk-studies-summary.csv")
studies_sorted <- studies_sum %>%
  mutate(study = factor(study, levels = paste0("turk", c(4:7, 10:11, 13:14)))) %>%
  filter(study %in% paste0("turk", c(4, 10, 14))) %>%
  group_by(study, pic_id, pic_name) %>%
  arrange(desc(n)) %>%
  filter(obs_plot_location != response_no) %>%
  mutate(sorted_panel = row_number(), prop = n/sum(n)) %>%
  ungroup()

theoretical_distribution_plot <- prior_sim %>%
ggplot() +
  geom_path(aes(x = idx, y = prob, group = interaction(rep, alpha)), alpha = .05) +
  facet_wrap(~label, labeller = label_parsed, nrow = 3) +
  scale_x_continuous(expression(paste("Panels, ordered by selection probability ", theta[i]))) +
  scale_y_continuous(expression(paste("Panel selection probability ", theta[i]))) + 
  ggtitle("Dirichlet simulations")

turk_studies_plot <- studies_sorted %>%
  ggplot(aes(x = sorted_panel, y = prop, group = pic_id)) +
  geom_path(alpha = .05) + facet_wrap(~study, nrow = 3) +
  # scale_x_continuous(expression(paste("Panels, ordered by observed selection probability ", theta[i]))) +
  scale_x_continuous("") + 
  scale_y_continuous(expression(paste("Panel selection probability ", theta[i]))) + 
  theme(axis.title.y = element_blank(), axis.text.y = element_blank()) + 
  ggtitle("Vis inference studies")

gridExtra::grid.arrange(theoretical_distribution_plot, turk_studies_plot, widths = c(3, 1))
@

\svp{From figures \ref{fig:simplex} and \ref{fig:prior-predictive}, it is evident that $\alpha$ provides some information about how many panels are likely to attract participant attention.}

% ---- Stuff left over from the lineups as hypothesis tests section ------------
% This stuff is supposed to be mostly integrated into admininstration after the
% scenarios are defined.
% Goal of the administration section is to motivate the differences in the models
% and make the point that Scenario 1 is a special case of Scenario 3 where there
% is no dependence; as a result, we don't have to bother modeling the selection
% probabilities because they don't carry over between lineup evaluations.
\hh{I believe a merge went wrong at this point. XXXX I re-included the previous items.}

\hh{Main assumption of the paper:  the probability that participants select  null plots from a lineup follows a Dirichlet distribution. Likely $\alpha < 1$ because some null plots are more interesting than others and attract more selections than one would expect under a uniform distribution (or even pick probabilities of $1/m$) }

\hh{XXX up for grabs}
\hh{Note aside: $c/K$ is the direct ML estimate for $\theta_i$. Obviously, only $K+1$ different levels are occurring in a lineup, with lots of this values being 0, which makes a direct ML estimate of $\bm\theta$ a poor approach to estimating $\alpha$ reliably.}

\hh{XXX This still needs a home}
\hh{We should probably define `interesting' as  $c$-interesting: A lineup panel is $c/K$ interesting if at least $c$ out of $K$ participants select the panel as the most different. This gives us an objective way to let evaluators determine what is interesting.}

\hh{Our (unverified and probably unverifiable) assumption is further that the exact value of $\alpha$ is determined by the null generation process as well as the type of chart  we use to display the data and the null plots.}

\hh{XXX Do we need to show some evidence for that? We have tons of data to back this statement up from our turk studies.}

% ------------------------------------------------------------------------------

\subsection{Lineup Administration}\label{sec:scenarios}
% Types of lineups
%\citet{buja:2009} introduced two types of lineups: Rorschach lineups, which contain only null plots, and standard one-target lineups, which contain $m$ panels, $m-1$ of which are null plots, and one which shows the real data.
%\citet{vanderplas:2017} introduced the two-target lineups\svp{, which can be used to test the visual salience of two competing effects.}
% Types of lineup evaluations
In addition to different types of lineups, there are different \dc{ways that an analyst can run a lineup experiment.} Three possibilities are detailed below and also illustrated in \autoref{fig:scenarios}.

\begin{description}
\item [Scenario 1] $K$ different lineups are shown to $K$ independent individuals.
In this scenario, both the data and the null plots in each generated lineup are distinct from those in every other lineup.
This scenario is only practical when using purely simulated data (for both the data and null plots) or data large enough to allow for subsampling to generate $K$ different data plots.
Under \svp{Scenario 1}, we can consider the number of target plot selections $t$ out of $K$ total evaluations, where each lineup evaluation is a bernoulli trial; the total number of data plot evaluations can then be modeled as a Binomial distribution with selection probability $1/m$ (for a single target lineup) \citep{majumder2013validation}.

\item [Scenario 2] $K$ different sets of null plots are shown to $K$ independent individuals; the same data plot is used in each lineup.
Alternately, $L$ sets of lineups are shown to $K > L$ individuals.
In Scenario 2, there are dependencies introduced by reuse of the data or the lineups, providing an intermediate case between the two extremes of Scenario 1 and Scenario 3.

\item [Scenario 3] The same lineup is shown to $K$ independent individuals.
This scenario is the most common scenario in the lineup experiments which have been completed to date \citep{hofmann2012graphical,roychowdhury:2012,majumder2013validation,loyAreYouNormal2015,vanderplas:2017}.
In this scenario, lineup evaluations by independent viewers are not independent because the viewers are evaluating the same combination of 19 null plots and one data plot.
Any peculiar features which arise in a null plot may cause participants to select that null plot over the data plot; it is likely that where one individual makes this choice, others might as well.
Thus, in Scenario 3, which is the most common lineup experiment scenario, it is not reasonable to assume that all panels are equally likely to be selected under the null hypothesis.
\end{description}

Scenario 3 is the primary motivation for the model which we will develop in the next section: while we cannot consider the panels in each lineup as equally likely to be selected, we can model the individual selection probabilities using a hierarchical model.

<<scenarios, eval = T, echo=FALSE, out.width='\\textwidth', fig.width=12, fig.height=4, fig.cap = "Illustrations of scenarios 1 and 2. Left column shows what three different evaluators would see under scenario 1, and the right column shows what three different evaluators would see under scenario 2. In scenario 1, all nulls and data plots are different, while in scenario 2 only the nulls differ.  (Scenario 3 would have all three lineups the same.) The location of the data plot may vary from one evaluator to another.">>=
set.seed(2020)
df <- tibble(x=runif(50)) %>%
  mutate(y1 = -4*(x-0.5) + rnorm(50)) %>%
  mutate(y2 = ifelse(x<0.5, (x-0.5) + 5 + rnorm(50),
                     (x-0.5) - 5 + rnorm(50)))
l1 <- lineup(null_permute('y1'), df, n=5) %>%
  mutate(subject = "evaluator 1")
l2 <- lineup(null_permute('y1'), df, n=5) %>%
  mutate(subject = "evaluator 2")
l3 <- lineup(null_permute('y1'), df, n=5) %>%
  mutate(subject = "evaluator 3")
l <- bind_rows(l1, l2, l3)
p1 <- ggplot(l, aes(x, y1)) +
  geom_point() +
  facet_grid(subject ~ .sample) +
  theme(aspect.ratio=1,
        axis.ticks = element_blank(),
        axis.text = element_blank()) +
  xlab("") + ylab("") +
  ggtitle("Scenario 2")

df <- tibble(x=runif(50)) %>%
  mutate(y1 = -4*(x-0.5) + rnorm(50)) %>%
  mutate(y2 = ifelse(x<0.5, (x-0.5) + 5 + rnorm(50),
                     (x-0.5) - 5 + rnorm(50)))
l1 <- lineup(null_permute('y1'), df, n=5) %>%
  mutate(subject = "evaluator 1")
df <- tibble(x=runif(50)) %>%
  mutate(y1 = -4*(x-0.5) + rnorm(50)) %>%
  mutate(y2 = ifelse(x<0.5, (x-0.5) + 5 + rnorm(50),
                     (x-0.5) - 5 + rnorm(50)))
l2 <- lineup(null_permute('y1'), df, n=5) %>%
  mutate(subject = "evaluator 2")
df <- tibble(x=runif(50)) %>%
  mutate(y1 = -4*(x-0.5) + rnorm(50)) %>%
  mutate(y2 = ifelse(x<0.5, (x-0.5) + 5 + rnorm(50),
                     (x-0.5) - 5 + rnorm(50)))
l3 <- lineup(null_permute('y1'), df, n=5) %>%
  mutate(subject = "evaluator 3")
l <- bind_rows(l1, l2, l3)
p2 <- ggplot(l, aes(x, y1)) +
  geom_point() +
  facet_grid(subject ~ .sample) +
  theme(aspect.ratio=1,
        axis.ticks = element_blank(),
        axis.text = element_blank()) +
  xlab("") + ylab("") +
  ggtitle("Scenario 1")
grid.arrange(p2, p1, ncol=2)
@

\hh{XXXX}
\hh{Null hypothesis: the data plot does not stand out from the null plots in the sense that not `enough' viewers select the data plot as the most different from a lineup.}

\hh{Alternative hypothesis: the data plot does stand out from the null plots.}

\hh{Definition of visual p value}

\hh{Under scenario 1 this general approach simplifies to Binomial, see appendix?}

\section{\dc{Significance Calculation} Model Specification}

Consider a lineup \svp{experiment} under scenario 3, i.e.\  the same lineup containing $m$ panels, independently evaluated $K$ times.
Define $c = (c_1, ..., c_m)$ to be the counts corresponding to the set of $K$ evaluations, where $c_i$ is the number of times a participant selected panel $i$, \dc{where}\svp{XXX is the where, ... where, ... construction awkward to anyone else?}
$0 \le c_i \le K$ for all $1 \le i \le m$ and $\sum_i c_i = K$. (This assumes that evaluators must make a selection, and if they make more than one selection, their count is weighted to sum to 1. The derivations below accommodate fractional counts.)

The Multinomial $(K, \theta)$ distribution, with probability mass function given as:

\begin{align}\label{eqn:multinomial-pmf}
f(\bm{c}|K, \bm{\theta}) & = \frac{K!}{c_1! \cdots c_m!} \prod_{i=1}^m \theta_i^{c_i}
\end{align}

\noindent is a natural model for the counts $c_i$, where $K$ describes the number of evaluations and $\bm{\theta} = \theta_1, ..., \theta_m$ describes the probability that each panel $i=1, ..., m$ is selected.
% add a  transition/ref back to the alpha section for clarity
\svp{As discussed in \autoref{sec:alpha}}, the panel selection probabilities $\bm{\theta}$ can be modelled using a Dirichlet distribution with concentration hyperparameter $\bm{\alpha} = (\alpha_1, ..., \alpha_m)$.
% Simplifying the phrasing here a bit
\svp{We do not know where a specific panel will be placed when the lineup is initially generated, so we use a} symmetric  Dirichlet distribution, with $\alpha_i = \alpha, i = 1, ..., m$, that is, the concentration hyperparameter is constant. 

The density function of the symmetric Dirichlet distribution is given as
\begin{align}\label{eqn:dirichlet-pdf}
f(\bm{\theta} \mid \alpha) & = \frac{\left(\Gamma(\alpha)\right)^m}{\Gamma(m\alpha)} \prod_{i=1}^m \theta_i^{\alpha - 1},
\end{align}
\hh{where $\Gamma(.)$ is the Gamma function defined as }
\begin{align*}
\Gamma(z) = \int_0^\infty x^{z-1}e^{-x}dx.
\end{align*}
\hh{(Note that, the Gamma function is equal to the factorial function $\Gamma(n) = (n-1)!$ for integer values of $n$.)}

\dc{Thus,} for the observed plot selections
$(c_1, ..., c_m)$, and assumimg hyperparameter $\alpha > 0$, we specify a Beta-Multinomial model (call this model BM) as:

\begin{align}\begin{split}\label{eqn:full-model-specification}
\bm{\theta} \mid \alpha &\sim Dirichlet(\bm\alpha)  \\
\bm{c} \mid \bm{\theta} & \sim Multinomial(\bm\theta, K)\\
\end{split}\end{align}

%where $Multinomial(\bm\theta, K)$ \svp{is defined as in \autoref{eqn:multinomial-pmf}} and $Dirichlet(\bm\alpha)$ is defined as in \autoref{eqn:dirichlet-pdf}.
\svp{The joint distribution of $\bf c$, $\bf \theta$ is then a Multinomial-Dirichlet mixture distribution.} %\dc{We will refer to this as {\bf model MD}, for brevity in later explanations.}

\svp{If we were interested in the value of $\bm\theta$ and wanted to take a Bayesian approach, we would use the conjugate relationship between the Multinomial and Dirichlet distributions to get a posterior distribution }
% Using the conjugate relationship between the Dirichlet and Multinomial distributions, we then get the posterior distribution
of $\bm{\theta}$ given $c$ and $\alpha$ as Dirichlet$(\bm{c + \alpha})$.
\svp{However,} \dc{the primary purpose is to obtain} \svp{a visual p-value from this mixture model,} \dc{which} \svp{does not require that we conduct inference on $\bm\theta$. Rather, }
\svp{the use of this model in evaluating lineups with one or more target plots rests on the assumption that the Dirichlet distribution is symmetric; that is, while not all panels are equally likely to be selected, there is no a priori belief that the panels systematically differ.}

\svp{Restated in hypothesis testing terms, our null hypothesis is that $\bm\alpha = \alpha * (1)_{m\times 1}$.}
\svp{If the lineup contains a target plot, that target plot should be overwhelmingly selected, producing counts which are not likely to occur under the assumption of symmetry in $\bm\alpha$.}

% \hh{XXX We also need to describe how the model specification relates to a lineup test. Because what is written out are only the null models. }
\dc{This approach differs from the method in} \citet{majumder2013validation}, where the number of target plot identifications were compared with the aggregate number of null plot identifications. 
However, that approach can be considered to be equivalent to the marginal distribution of $c_i$, which is a special case of model BM.%, where $i \in 1, ..., m$ is the index of the target panel in the lineup. 
For a total of $K$ evaluations, and $0 \le c_i \le K$ target plot evaluations, the mondel BM simplifies to a Beta-Binomial model:

\begin{align}\begin{split}\label{eqn:marginal-model-specification}
\theta_t \mid \alpha &\sim Beta(\alpha, (m-1)\alpha) \\
C_i \mid \theta_i & \sim Binomial(\theta_i, K),\\
\end{split}\end{align}

with the distribution of $\theta_i$ given $c_i$ and $\alpha$ as Beta$(c_i + \alpha, K - c_i + (m-1)\alpha)$.\dc{XXX Changed t to i, should be same as previous equations, I think}

Examining the parameters of either the full (Eq. \ref{eqn:full-model-specification}) or marginal model (Eq. \ref{eqn:marginal-model-specification}) specifications, tells us that $\alpha$ provides the equivalent of pseudo-observations for each plot. That is, the effect of $\alpha$ is equivalent to adding $\alpha$ identifications to each panel in the lineup.
When $\alpha$ is small, these pseudo-observations have relatively little influence, but when $\alpha$ is large, the pseudo-observations can quickly dwarf any information provided by the data.
This is particularly true for the marginal Beta-Binomial model, where the equivalent of $(m-1)\alpha$ pseudo-observations are added.\dc{XXX can we think of this as noise dominating signal?}
A \svp{lineup} might be evaluated between 10 and 30 times, and with a $m=20$ \svp{panel} lineup, even $\alpha = 1$ can easily dominate the participant selection data.

% In addition to the pseudo-observation interpretation,
\dc{The parameter} $\alpha$ \dc{can} \svp{also} \dc{be considered to be possessing the} information about the number of panels in a lineup {\it which are likely} to attract participant interest.
%It is useful to detour slightly from the discussion of visual inference to 
\dc{The next section explores} the impact and interpretation(s) of $\alpha$ in the context of statistical lineups.


\subsection{\dc{Effect of} $\alpha$ on Lineup Scenarios}\label{sec:scenario-alpha}

% Argument outline:
% 1. alpha provides information about how many panels attract participant attention
% 2. Participant attention is a function of visual difference perception, but it is also a function of the data generation method
% 3. Compare Scenario 1 vs. Scenario 3
%     a. Scenario 1: new panels with each new lineup; no dependencies between panels. Every panel is equally interesting (at least, under $H_0$). This corresponds to infinite $\alpha$, or, more explicitly, to $\theta = 1/m$.
%     b. Scenario 3: each participant evaluates the same lineup, so the relationship between the interest level of each panel is constant. This corresponds to finite $\alpha$, and generally, $\alpha \lt 1$, that is, all panels are not equally interesting.
% 4. The binomial model is effective in scenario 1, because we do not have any information about $\theta_i$ shared between subsequent lineup evaluations. In Scenario 3, however, we do, and thus, it becomes important to model that difference using the mixture model we propose in this paper.
% 5. If we work under Scenario 3, we should expect $\alpha$ to differ based on the data generation model and based on the form and aesthetic presentation of the plot. Thus, for each experiment, we need to estimate $\alpha$.

\svp{That not all panels in a lineup are equally interesting is a function of both the statistical generation method and the visual system.}
\svp{The lineup protocol may provide participants with some information about the hypothesis under investigation, using a question such as ``Which panel has the strongest trend?", but more often, we ask generic questions such as ``Which panel is the most different".}
The ability to identify stimuli as being different from one another is a fundamental part of cognition: the abstractions that allow us to use the terms `same' and `different' are fundamental to human intelligence~\citep{mingWhenThingsAre2017}.
\svp{When presented with a lineup and a generic prompt, the contrast between the visually interesting and uninteresting panel(s) help us to scaffold a mental representation of "same" and "different", ideally corresponding to the measure that is under investigation.}
When a lineup contains null plots with interesting visual features, there is the possibility that participants (who are not provided with the null and alternative hypotheses) may form a hypothesis that is not under investigation, focusing \svp{instead} on the randomly generated but visually interesting feature \citep[e.g ][]{vanderplas:2017}.
\svp{In this situation, the participant falls prey to a Type III error; that is, the right answer to the wrong question~\citep{kimball1957errors}}. \dc{XXX Can we also have a Type IV wrong answer to the wrong question? Thinking that a null is picked because of some feature not of interest.}
\svp{When the possibility of a Type III error is combined with the lineup administration scenario, however, there are implications for our understanding of the meaning of $\alpha$.}

\svp{Under Scenario 1, each participant sees an entirely different lineup: the data plot(s) and null plots are exchanged between each participant evaluation.
Thus, while there may be differences in the visual interest of each panel in any one lineup, these differences do not carry over to the next lineup.
While all panels in a single generated lineup may not be equally likely to be selected, we do not have any information or ability to quantify these differences.
In fact, in Scenario 1, it does not make sense to track any information beyond whether or not the data panel was selected: each evaluation is in effect a separate, independent Bernoulli trial.}
\svp{Our selection of $\alpha$ under this scenario goes beyond what might be considered a noninformative $\alpha=1$ (corresponding to uniformly distributed $\theta_i$ over the $m-1$ simplex).
Instead, because we are averaging over all panels which could be generated by the data and null models (as both the data plot and the null plots are exchanged every time), we can claim that every plot is strictly equally likely to be selected under $H_0$. In the Beta-Binomial mixture model, this corresponds to infinite $\alpha$.
As shown in \autoref{fig:vis-p-val-sensitivity-initial}, when $\alpha \rightarrow\infty$, the Beta-Binomial model converges asymptotically to the Binomial model (with $\theta = 1/m$) proposed in \citet{majumder2013validation}.}

<<vis-p-val-sensitivity-initial, fig.cap = "Sensitivity of visual p-value to selection of $\\alpha$ under the marginal beta-binomial model. Corresponding values for the binomial model are shown on the right side of the plot; as $\\alpha \\rightarrow\\infty$, the beta-binomial p-values converge to the binomial model p-value. XXXCan take out the dot Binomial value... from the top of the plot - i find it distracting as though its an actual data point.", fig.width = 8, fig.height = 5, out.width = "\\textwidth">>=
alphas <- 10^(seq(-3, 2, by = .01))
# data_breaks <- c(1:5, 6, 8, 10, 15, 20)
data_breaks <- c(1, 2, 3, 5, 7, 10, 15, 20, 25, 30)
K <- 30

color_pal <- RColorBrewer::brewer.pal(length(data_breaks), "Paired")

breaks <- c(10^seq(-3, 2, 1), 5*10^seq(-3, 1, 1)) %>% sort()
minor.breaks <- c(2.5, 7.5) * rep(10^seq(-3, 1, 1), each = 2)
labels <- sprintf("%.3f", breaks) %>% gsub("\\.?0{1,}$", "", .)

breaks <- c(breaks, 150)	
labels <- c(labels, "∞")

pv <- tidyr::crossing(alpha = alphas, C = data_breaks, K = K) %>%
  mutate(p = vis_p_value(C, K, alpha))
pv2 <- tidyr::crossing(C = data_breaks, K = K) %>%
  mutate(p = purrr::map2_dbl(C - 1, K, pbinom, prob = 1/20, lower.tail = F))

ggplot(pv, aes(x = alpha, y = p, color = factor(C), group = factor(C))) +
  annotate("segment", x =150, xend = 150, y = -Inf, yend = .8, color = "grey40", alpha = .5) +
  annotate("text", x = 150, y = .8,
           label = "Binomial", vjust = 0, hjust = .75) +
  annotate("segment", x = 1, xend = 1, y = -Inf, yend = .8, color = "grey40", alpha = .5) +
  annotate("text", x = 1, y = 0.8,
           label = expression(paste("θ ~ Uniform on m-1 simplex")), vjust = 0, hjust = .5) +
  geom_line(size = 0.75) +
  geom_point(aes(x = 150, y = p, color = factor(C), shape = "Binomial\np-value"), data = pv2) +
  scale_y_continuous("Visual p-value") +
  scale_x_log10(expression(alpha), breaks = breaks, labels = labels, minor_breaks = minor.breaks) +
  scale_color_manual(paste0("# Data Panel\nIdentifications\n(K =", K, ")"), values = color_pal) +
  scale_shape_discrete("") +
  geom_hline(yintercept = 0.05, color = "grey40") +
  guides(color = guide_legend(override.aes = list(shape = NA), order = 1),
         shape = guide_legend(order = 2)) +
  theme_bw() +
  theme(legend.position = c(0, 1), legend.justification = c(0, 1), legend.background = element_blank(), legend.box = "horizontal")
@


\svp{Under Scenario 3, however, each participant sees the same lineup, with the same data plot(s) and null plots.
In this scenario, we have enough information that we can model the $\theta_i$ across different lineup evaluations.
Because the perceptual mechanisms which determine visual interest are shared across participants, and the same null plots and data plot(s) are used, we must allow $\theta_i$ to vary.
The Dirichlet-Multinomial model \dc{do you mean BM model? you haven't previously defined DM model.} provides this flexibility through the introduction of the hyperparameter $\alpha$.} The general formula for calculating a visual $p$-value under \svp{the Beta-Binomial model appropriate for use in Scenario 3} is:
\begin{align}\label{eqn:beta-binomial}
p\text{-value} = P(C\geq c_i) = \sum_{x = c_i}^{K} \binom{K}{x} \frac{1}{B(\alpha, (m-1)\alpha)}\cdot B(x+\alpha, K-x+(m-1)\alpha)
\end{align}
where $c_i$ is the number of times the data panel was picked in $K$  evaluations of the lineup. \hh{$B(., .)$ is the Beta function defined as:}
\begin{align*}
B(a, b) = \int_0^1 t^{a-1} \cdot (1-t)^{b-1} dt \vspace{1in} \text{ where } a,b > 0.
\end{align*}
The derivation is in Appendix~\ref{app:pvalue}.

\dc{The visual $p$-value calculation} \svp{using \autoref{eqn:beta-binomial}, is dependent on the hyperparameter $\alpha$.}
\svp{We know from past studies \citep{loy2016variations,vanderplas:2017} \dc{XXX should you reference all the studies, because every one has had this phenomenon} that only a few lineup panels attract attention, even if all of the panels in a lineup are null plots.}\footnote{
\svp{In fact, it would make very little sense to use a Rorschach lineup under Scenario 1; with no shared information between different evaluations, there would be no reasonable way to aggregate the results.}}. \dc{XXX I don't think you need the footnote. And you could even drop the last part of the sentence, even if all nulls}
\svp{Combining this observation with} \autoref{fig:prior-predictive}, \svp{ we would expect that} $\alpha \ll 1$.

The value of \svp{$\alpha$ would be expected to vary \dc{based on various factors}: the null generating model, type of plot, and other aesthetic choices,  all of which could affect the visual distinctiveness of the null and actual data.}
In order to calculate visual p-values \svp{for lineups evaluated under Scenario 3}, we must match the \svp{underlying} data generation method and visual evaluation processes with an appropriate value of $\alpha$.

%
% A similar method is found in the \texttt{vinference} package, which calculates visual p-values by simulating draws of $\theta$ from a uniform distribution (corresponding to the assumption that $\alpha=1$, as shown in \autoref{fig:simplex})\citep{vinference}.
%
% \subsection{Hyperparameter Selection}
% \svp{In \autoref{sec:scenario-alpha}, we described the differences in visual p-value calculations for different lineup scenarios.}
% In the theoretical Multinomial-Dirichlet model in \autoref{eqn:full-model-specification}, the number of panels which could be expected to be visually different in a generalized lineup is a function of $\alpha$, the hyperparameter in \autoref{eqn:dirichlet-pdf} and \autoref{eqn:full-model-specification} (a derivation of this expectation is provided in Appendix \ref{app:expected}).
\svp{As it is difficult to design a null plot generating method which will result in a specific $\alpha$ value, in practice, we will need to select an appropriate $\alpha$ for a predetermined null plot generating model.}
% \svp{A lineup with null panels that are of similar visual interest would have a higher $\alpha$ value than a lineup with only one or two visually distinctive null panels in addition to the data panel.}
\svp{The selected} $\alpha$ modulates the calculated visual p-value, as shown in \autoref{fig:vis-p-val-sensitivity-initial}: \svp{when $\alpha$ is low, it is likely that there are one or more visually distinctive null plots, making it difficult to attribute data panel selections to definitive visual differences betweeen the null and data plots.}
\svp{When $\alpha$ is relatively high, however, there are likely to be more null plots which attract visual attention; in this situation, it is very easy to determine whether the data panel is visually distinct compared to the null panels.}
Clearly, the choice of $\alpha$ is critical.
% The simulated distributions in \autoref{fig:prior-predictive} are illustrative, \svp{it can be difficult to translate the results from \autoref{fig:prior-predictive} into a useful estimate of $\alpha$.}
% in practice, we do not usually have a good instinct for what a reasonable value of $\alpha$ would be for a particular lineup generation method.

\section{Estimation of \texorpdfstring{$\alpha$}{alpha}}\label{sec:est-alpha}

\hh{While it is generally possible to estimate $\alpha$ \citep{sirt, minka} directly based on proportions observed from panel selections in a lineup, these maximum likelihood approaches fail because of the large number of observed zeroes.}
\svp{Under Scenario 3, one consequence of our tendency to consider the same subset of interesting null panels is that many less interesting null panels have no participant selections.}
This problem is even more pronounced when $\alpha$ values are small \svp{and only one or two null panels attracts participant interest}.
\svp{As a result, methods for estimation of $\alpha$ are most likely to fail in precisely the region of the parameter space where lineup experiments typically operate.}

\svp{In order to avoid the issues with maximum likelihood estimation, in this paper, we propose a method for \emph{visual} estimation of alpha which is not hampered by the prevalence of 0-count values.
We also propose a formal method for estimating $\alpha$ based on the results of Rorschach lineup based testing.
In this section, we describe both methods, as well as an alternate use of the estimated $\alpha$ value to screen for problems in the null plot generation method.}


\svp{Both the visual and numeric methods for estimating $\alpha$ leverage the expected number of ``interesting" panels in a lineup.}

\svp{Let us first define the random variable $Z_c$, the number of panels selected more than $c$ times in $K$ evaluations of a $m$-panel lineup.}
\svp{The expected number of panels selected more than $c$ times, $E[Z_c]$, is provided in \autoref{eqn:ev-panel}. The derivation of $E[Z_c]$ from \autoref{eqn:full-model-specification} is provided in \autoref{app:expected}.}

\begin{equation}\label{eqn:ev-panel}
E[Z_c(\alpha)] = \frac{m}{ B(\alpha, (m-1)\alpha)} \cdot \sum_{x=c+1}^K \binom{K}{x} B(x+\alpha, K-x+(m-1)\alpha).
\end{equation}

\subsection{Visual Estimation of \texorpdfstring{$\alpha$}{alpha}}\label{sec:vis-estimation-alpha}

\svp{There have been several explorations of the use of visual statistics \citep{mostellerEyeFittingStraight1981, correllRegressionEyeEstimating2017, LAWRENCE1989172, meyerEstimatingCorrelationsScatterplots1992} as a supplement or an alternative to statistical inference.
% There are also studies which supplement available data with visual estimates \citep{hankin1988estimating}, incorporating both objective and subjective measurements into the same statistical model.
Visual estimates of correlation and linear regression are known to differ systematically from the numerical estimates, but not because the visual system is inaccurate or misleading.
Instead, estimates derived visually tend to discount the effect of outliers, producing a more robust estimate of the statistical quantity of interest.}
\svp{In this application, we expect that visual estimation of $\alpha$ based on the expected number of ``interesting" panels will produce a more robust estimate of $\alpha$ than the numerically unstable maximum likelihood estimates.}

\svp{In a lineup experiment, we typically compare the selections of the data panel relative to the \emph{aggregate} selections of null panels, using the marginal Beta-Binomial model.
While this makes the calculations much simpler, because there is no need to keep track of the locations and selections of individual null plots, it does throw away some information; namely, the distribution of participant interest in the null panels.
This visual estimation method is predicated on utilizing that discarded information to estimate $\alpha$.}

\svp{
In \autoref{fig:prior-predictive}, it is clear that $\alpha$ is directly related to the number of panels which are selected as interesting by participants.
There is some variability around how many times each panel was selected, but the number of panels which attract participant attention is fairly consistent across multiple simulations.
We propose estimating $\alpha$ visually from the number of null panels which attract participant interest, recovering some of the information discarded and using that information to attenuate our visual p-value.
}

\svp{
There are at least two immediate concerns with this proposal: first, we must quantify ``participant interest" - is a single participant's selection sufficient?
Second, we must handle the case where the data plot is the only panel selected; this corresponds to overwhelming evidence that the null hypothesis is incorrect, but it leaves us with no ability to estimate $\alpha$.
}

\svp{
As implied at the beginning of \autoref{sec:est-alpha}, the mathematical quantity associated with `attract participant interest' would correspond to a threshold: if a panel is selected at least $c$ times out of $K$ total evaluations, it is interesting.
Determining what the value of the threshold $c$ should be is another matter.
One broadly applicable approach would be to let $c = K/m$; that is, setting the threshold $c$ to be greater than the expected number of selections under the Binomial model assumption that all panels have selection probability $1/m$.
}

\svp{
In the case where a tested lineup has selections which overwhelmingly favor the data plot, we have a problem: the lineup is likely significant (based on the overwhelming evidence that the data plot attracts the most visual interest), but we cannot estimate $\alpha$ because there are insufficient null panel selections.
In this case, estimation of $\alpha$ will depend on creation of a Rorschach lineup (that is, a lineup consisting entirely of plots generated under the null hypothesis).
This process is described in more detail in \autoref{sec:rorschach-est-alpha}.
% Having this Rorschach lineup evaluated separately will provide an estimate of $\alpha$ which is unaffected by the data plot; then, a p-value for the data lineup can be computed using the $\alpha$ estimated from the Rorschach lineup.
}

\svp{
As it is rare for the data plot to be the only panel to attract participant attention, however, we can usually recover information about $\alpha$ from the null panels in the same lineup.
This is a more efficient use of participant time, as we do not have to ask them to evaluate two separate lineups in order to determine the visual p-value for a plot.
Using null panel selections hinges on a property of the Dirichlet distribution: when one category is removed from consideration, the remaining categories still maintain a reduced-dimension Dirichlet distribution with the same parameter $\alpha$.
A proof of this property is provided in the Appendix XXXX - is it worth it?.
}
% This method is based on the assumption that during the creation of a null plot generating model (and viewing of lineups assembled from that model), the experimenter generally has an estimate of roughly how many null plots in a lineup tend to be visually interesting.


<<alpha-sim-curve, cache = F, fig.width = 8, fig.height = 4, out.width = "\\textwidth", fig.cap = "Average number of panels selected more than once for a range of $\\alpha$ values. Each point represents 10 simulations of lineups with $K=30$ evaluations. The line in blue shows the expected number of panels selected more than once as given in \\autoref{eqn:differentPanels}. Bands are shown in alternating grey and white corresponding to a discretized heuristic for selection of $\\alpha$ when $K=30$.">>=
set.seed(2501072)
interest_threshold <- 1
alphas <- 10^(seq(-3.5, 2, by = .01)) # seq(0.001, 0.5, by = .001)

number_panels <- function(alpha, c=1, m = 20, K=30) {
  x <- (floor(c) + 1):K
  summation <- choose(K, x) * beta(x + alpha, K - x + (m - 1)*alpha)

  m/beta(alpha, (m - 1)*alpha)*sum(summation)
}

sim_interesting_panels <- function(c = m/K, N_points = 5, m = 19, K = 30, point_avg_sims = 10, alphas = alphas) {
  # Each point (of N_points) is an average of point_avg_sims separate lineups
  # First, generate all of the lineups and count the number of interesting panels
  df <- tibble(alpha = alphas,
               plot_sels = purrr::map(alpha, sim_lineup_model,
                                      N = N_points*point_avg_sims, K = K),
               interesting_panels = purrr::map(
                 plot_sels,
                 ~tibble(n_interesting = colSums(.x > c),
                         rep = 1:ncol(.x) - 1))
  ) %>% unnest(interesting_panels)

  # Then, average the panels together a bit
  df2 <- df %>%
    mutate(point_num = (rep - (rep %% point_avg_sims))/N_points) %>%
    group_by(alpha, point_num) %>%
    summarize(n_interesting = mean(n_interesting))
}

# Create polygons that connect a function to the y and x axes
lag_polys <- function(data) {
  x = data$x
  y = data$y
  minval = 10e-8
  bind_rows(
  tibble(
    x = c(minval, x[1], x[2], minval, minval),
    y = c(y[1], y[1], y[2], y[2], y[1]),
    type = "h"
  ),
  tibble(
    x = c(x[1], x[2], x[2], x[1], x[1]),
    y = c(-Inf, -Inf, y[2], y[1], -Inf),
    type = "v"
  ))
}

# Get theoretical function
model_df <- tibble(alpha = alphas,
                   n_sel_plots = alphas %>% map_dbl(number_panels, c = interest_threshold)
)

# Get simulated data
prior_pred_mean <- sim_interesting_panels(c = interest_threshold, alphas = alphas) %>%
  arrange(alpha) %>%
  mutate(label = sprintf("alpha == %f", alpha) %>%
           factor(levels = sprintf("alpha == %f", alphas), ordered = T))

# Get possible breakpoints for alphas and panels
panel_sel_breaks <- c(1.5, 3.5, 5.5, 7.5)
possible_breakpoints <- model_df %>%
  filter(round(n_sel_plots - floor(n_sel_plots), 1) == .5 |
           round(n_sel_plots - floor(n_sel_plots), 1) == 0) %>%
  mutate(tmp = floor(n_sel_plots*2)/2, dist = abs(n_sel_plots - tmp)) %>%
  group_by(tmp) %>%
  filter(dist == min(dist)) %>%
  filter(tmp %in% panel_sel_breaks) %>%
  ungroup() %>%
  mutate(band = floor(.5 + row_number()/2))

# polygons for the grey-and-white bands
bands <- possible_breakpoints %>%
  rename(x = alpha, y = n_sel_plots) %>%
  nest(data = -band) %>%
  mutate(polys = purrr::map(data, lag_polys)) %>%
  unnest(polys)

# minor break points
mb <- crossing(x = c(2.5, 5, 7.5), y = 10^(seq(-4, 5))) %>%
  mutate(z = x*y) %>%
  `[`("z") %>%
  unlist() %>%
  as.numeric

# text labels for polygon bands
band_label_pos <- panel_sel_breaks + 1 # this is a good default but may need customizing
band_labels <- tibble(
  y = band_label_pos,
  x = min(alphas),
  label = c("2-3", "4-5", "6-7", "8+ Interesting panels")
)

# Finally, the actual plot
ggplot() +
  geom_polygon(aes(x = x, y = y, group = interaction(type, band)), data = bands, fill = "grey", alpha = 0.5) +
  geom_point(aes(x = alpha, y = n_interesting),data = prior_pred_mean, alpha = .05) +
  geom_line(aes(x = alpha, y = n_sel_plots), data = model_df, color = "blue", size = 1) +
  scale_x_log10(name = expression(alpha), breaks = c(0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000),
                minor_breaks = mb,
                labels = 10^(seq(-3, 4))) +
  geom_text(aes(x = x, y = y, label = label), data = band_labels, hjust = 0, color = "grey30") +
  coord_cartesian(xlim = range(alphas)) +
  scale_y_continuous(name = "Average number of panels with >1 selection", breaks = 1:100)

@

\svp{
Let us start with a simulation using the Dirichlet-multinomial model in \autoref{eqn:full-model-specification}, and assuming that the lineup experiment we are planning to conduct has a standard ($m = 20$ panel, $m_0 = 19$ null plot) lineup with $K_0=30$ null panel selections out of $K=40$ evaluations.
The heuristic we propose for \svp{ad-hoc} estimation of $\alpha$ utilizes the plot shown in \autoref{fig:alpha-sim-curve}.
}
\begin{enumerate}
\item Using a visual display with both simulated values and the expected value for the situation ($c = 1, m_0 = 19, K_0 = 30$), such as that shown in \autoref{fig:alpha-sim-curve}, determine ranges of interesting null panel counts which correspond to about 4 levels of null panel selection activity. In \autoref{fig:alpha-sim-curve}, these levels are 2-3, 4-5, 6-7, and 8+ panels with more than $c=1$ selection.
% Simulate, for each potential value of $\alpha$, the number of panels selected by a number of participants exceeding an interest threshold $c$. In \autoref{fig:alpha-sim-curve}, $K_0/m_0 = 30/19$, so $c \approx 1.58$).
% It may be helpful to average the results of several simulations together to reduce the variability and make the underlying trend more visible.
% \hh{The simulation captures the variability around the expected number of `interesting' panels}\svp{.}

If only one null panel is selected more than $c$ times, and there are a reasonable number of null panel selections overall, this may be a sign that the null plot generation method is unsuitable.  The case where only one null panel is selected is handled separately; discussion of this case is deferred to \autoref{sec:bad-null}. For now, it is sufficient to know that this is why we have created a separate band for the case where only one null plot attracts significant participant interest.

\item Using the simulated selected panel counts, find the band which is most consistent with the number of null panels selected more than $c$ times in the lineup. For instance, if there were three null panels with more than $c$ selections, we would use a range of 2-3 panels.

Use of a range instead of the single point estimate is intended to account for some of the variability resulting from the use of a single lineup with non-deterministic $K_0$ null panel evaluations.
In a simulation, it is easy to increase $N$ until the results no longer change; this is expensive and much more time consuming when using human evaluations and setting $K$ instead of $K_0$ in the experimental design.

\item Select an $\hat\alpha$ value corresponding to the selected band. \svp{For instance, if our selected lineup contained 3 interesting null panels}, we might use $\hat\alpha = 0.075$, as it approximately corresponds to $Z_c = 3$; we should compare to $\alpha = 0.02$ and $\alpha=0.1$ (the approximate outer range of $\alpha$ for our band) to get a sense of the sensitivity of our p-value to $\alpha$.

\item A plot such as the one shown in \autoref{fig:vis-p-val-sensitivity-initial2} may be helpful when assessing the sensitivity of the visual p-value to different values of $\alpha$ in each band. \autoref{fig:vis-p-val-sensitivity-initial2} is a segmented version of \autoref{fig:vis-p-val-sensitivity-initial}; each panel corresponds to the bands of interesting panel counts selected in step 1.

Locate the relevant panel of the plot, and, using the number of target panel selections, determine whether the visual p-value calculation is conclusive for every $\alpha$ in the panel. If it is, then it is safe to draw a strong conclusion; if not, it may be useful to use a secondary experiment to more precisely estimate $\hat\alpha$, as discussed in \autoref{sec:rorschach-est-alpha}.

In this case, we have 10 target selections ($K = 40, K_0 = 30$), and 3 null plots of 19 which were selected more than once. This corresponds to a visual p-value that will not be significant for any range of $\alpha$ in our selected band, so we do not need to run any secondary experiments to more precisely estimate $\alpha$.

\end{enumerate}

<<vis-p-val-sensitivity-initial2, fig.cap = "Sensitivity of visual p-value to selection of $\\alpha$ under the beta-binomial model, for a $m=20$ panel lineup with $K=40$ evaluations. Data picks which result in ambiguous results under the discretized bands of $\\alpha$ values are highlighted in red. At any particular $\\alpha$ level, there are only a few values which result in an inconclusive results.", fig.width = 8, fig.height = 5, out.width = "\\textwidth">>=
alphas <- 10^(seq(-3, 2, by = .01))
data_breaks <- 1:40
K <- 40
m <- 20

cuts <- c(-Inf, .02, .05, .1, .35, 1, 10, Inf)
cuts <- c(-Inf, possible_breakpoints$alpha, Inf)
labels <- c("0-1 Interesting null panels", "2-3 Interesting null panels", "4-5 panels", "6-7 panels", "8+ Interesting null panels")

pv <- tidyr::crossing(alpha = alphas, C = data_breaks, K = K) %>%
  mutate(p = vis_p_value(C, K, alpha)) %>%
  mutate(
     panel = cut(alpha, breaks = cuts, labels = labels)
     ) %>%
   group_by(C, K, panel) %>%
   mutate(
        type = ifelse(
          all(p > 0.05), "indicates no significance",
          ifelse(all(p < 0.05), "indicates significance",
          "is inconclusive")
         )
   )

labels_data <- pv %>%
   group_by(panel) %>%
   filter(
     alpha == max(alpha)
   )

ggplot(pv, aes(x = alpha, y = p, group = factor(C))) +
  facet_wrap(~panel, scales = "free") +
  geom_line(size = .8, aes(colour = type)) +
  scale_y_continuous("Visual p-value") +
   scale_x_log10(expression(alpha),
                 expand = expansion(mult = c(0.05,0.25))) +
  geom_hline(yintercept = 0.05, color = "black") +
  ggrepel::geom_label_repel(
     data = labels_data %>% group_by(panel, type) %>%
        filter(((type == "indicates no significance") & (C == max(C))) | ((type == "indicates significance") & (C == min(C)))),
     aes(label = C), color = "grey30", hjust = 0, nudge_x = 0.05, size = 3, alpha = 0.8,
         min.segment.length= 0, label.padding = 0.1, direction = "y") +
   theme_bw() +
   geom_label(label = paste0("# data picks\n (out of K = ", K, ")"),
              aes(x = .0010, y = .09), size = 3,
         data = labels_data[1,], hjust = 0, vjust = 1) +
   scale_colour_manual("Number of data picks ...",
                       values = c("grey70", "grey40", "red")) +
   theme(legend.position = c(.99, 0.45), legend.justification = c(1, 1))

@


\svp{
In \autoref{fig:vis-p-val-sensitivity-initial2}, we show the implications of the visual selection method for each band of $\alpha$ values in terms of the number of target plot selections necessary to achieve statistical significance at the $p=0.05$ level.
Due to the discretization of the expected number of panels with more than $c$ selections, each range of $\alpha$ values is ambiguous for one or more potential data panel selection counts; these values are shown in red, with labeled thresholds for nonsignificance and significance.
In the unfortunate situation where the estimated $\hat\alpha$ produces an inconclusive result, the experimenter has two options.
The inexpensive, conservative approach is to declare any inconclusive results to be nonsignificant, in effect using the smallest $\alpha$ value corresponding to the approximate number of panels selected.
Alternately, the experimenter could use the method described in \autoref{sec:rorschach-est-alpha} to produce a more precise $\hat\alpha$ which would provide definitive results, at the cost of conducting a secondary study.
}

\svp{By estimating $\alpha$, we produce visual p-values which are calibrated based on the specific null plot generation method.
In most cases, we get the improved calibration for free, because we can obtain this information from the null panels in one or two target lineups.
Occasionally, either because the signal in the data plot is too strong, or because the visual estimation method for $\alpha$ produces a range of p-values which are inconclusive given the number of target plot selections, we may need to invest additional effort in order to generate a precise $\hat\alpha$ estimate numerically.}

\subsection{Numerical Estimation of \texorpdfstring{$\alpha$}{alpha}}\label{sec:rorschach-est-alpha}

\svp{If the visual method of $\alpha$ estimation is inconclusive, or there are insufficient null panel selections to estimate $\alpha$ visually, \autoref{eqn:differentPanels} can be used to generate a more precise estimate of $\alpha$ with a secondary study consisting of one or more Rorschach lineups evaluated $K$ times each.
To ensure validity of the estimated $\alpha$, the Rorschach lineups should use the same null data generating mechanism used in the standard lineup.
Then, the average number of different panels selected by more than $c$ participants can be calculated from the secondary study data; numerical optimization can be used to obtain $\hat\alpha$ from this information.
Note that if on average only one null panel is selected, the estimated $\hat\alpha$ is not reliable: \autoref{eqn:differentPanels} does not have the sensitivity to differentiate the results of a lineup with $\hat\alpha = 0.001$ from the results of a lineup with $\hat\alpha = 0.01$; this is also apparent on the left side of \autoref{fig:alpha-sim-curve}.
When the estimated $\hat\alpha$ is extremely small, this is a signal that there is a problem with the null plot generation method; this case is described in more detail below.}

\svp{The numerical estimation approach does require each Rorschach lineup to have the same number of null plot evaluations, so that the experimentally determined average number of interesting panels is consistent and the same reference distribution can be used.
In contrast to the reference distribution used in \autoref{sec:vis-estimation-alpha}, the reference distribution in this approach is one with $m$ null panels.
The previous approach used $m_0$ null panels because when the data plot is excluded from the lineup, there are only $m_0$ null plots remaining.
In a Rorschach lineup, however, there are $m$ null panels which may be selected by participants.
}
Studies using visual inference may be relatively small (that is, with few participant lineup evaluations), which would make a formal secondary study to precisely determine $\hat\alpha$ cost prohibitive, but there is no doubt that a full study of Rorschach lineups would produce a more precise estimate of $\alpha$ compared to the visual method using discrete bands determined from \autoref{eqn:differentPanels}.

\subsection{Screening null generation methods}\label{sec:bad-null}
\svp{When only one null plot in a Rorschach lineup is visually interesting, we encounter two problems.
First, we cannot estimate $\hat\alpha$ with any real precision (visually or numerically), because many different $\alpha$ values below $\alpha\approx 0.025$ could give rise to a situation where only one panel is visually interesting.
Second, if there is only one interesting null panel in a Rorschach lineup, the equivalent one-target lineup would have between 1 and 2 interesting panels. The number of interesting panels in the data plot would depend on whether the interesting null plot is the null replaced by a data plot.
If the interesting null is replaced by the data plot, we would expect that the count values would look similar to those produced when evaluating the Rorschach lineup, but even if it is not, the distribution of counts might not differ enough to show statistical significance.
The lineup hypothesis testing method is predicated on the ability to visually distinguish a Rorschach lineup from a lineup with a data target, but a method which sporadically generates overwhelmingly interesting null plots provides insufficient grounds for rejection of the null hypothesis.}

\svp{An extremely low $\hat\alpha$ value (estimated visually or numerically) would indicate a null plot generation method which should be reassessed because it generates plots which attract highly variable amounts of visual interest from participants.
One example of such a null plot generating method would be the method described in \citet{vanderplas:2017}, which occasionally generated null plots which were missing important visual signals (such as a cluster consisting of one or two points, and a corresponding missing bounding ellipse).
Estimation of $\alpha$ provides us with a way to screen for bad null plot generation methods in addition to providing us with more accurate estimates of visual p-values.}

\svp{We can see from \autoref{fig:vis-p-value-sensitivity-initial} that the proposed method will generate p-values which are more moderate than the simpler Binomial model that does not involve the extra step of estimating $\alpha$. In the next section, we explore the practical implications of this method by examining actual lineups which were tested experimentally and the visual p-values calculated using each method.}

\section{Example}
<<example-setup, cache = T, include = F>>=
options(digits = 3)
vis_p_value <- function(C, K, alpha = 1, m = 20){
  single_p <- function(cc, kk, aa, mm) {
    x <- cc:kk
    sum(exp(lchoose(kk, x) - lbeta(aa, (mm - 1) * aa) + lbeta(x + aa, kk - x + (mm - 1) * aa)))
  }

  df <- tibble(cc = C,
               kk = K,
               aa = alpha,
               mm = m) %>%
    unnest() %>%
    mutate(p = purrr::pmap_dbl(., single_p))
  df$p
}
vis_p_value_orig <- function(C, K, m = 20){
  single_p <- function(cc, kk, aa, mm) {
    x <- cc:kk
    sum(exp(lchoose(kk, x) - x*log(mm) + (kk-x)*log(1-1/mm)))
  }

  df <- tibble(cc = C,
               kk = K,
               mm = m) %>%
    unnest() %>%
    mutate(p = purrr::pmap_dbl(., single_p))
  df$p
}


exdat <- readr::read_csv("data/turk6_60_96_1_8.csv")

# Generate a null lineup with the same 19 null plots + one extra null
exdat2 <- mutate(exdat, group = ifelse(.sample == 8, sample(group, n()), group))

studies_sum <- readr::read_csv("data/all-turk-studies-summary.csv")

# Number of null plots selected (out of 19)
turk6df <- filter(studies_sum, study == "turk6") %>%
  group_by(pic_name) %>%
  mutate(n_tot = sum(n)) %>%
  filter(n >= 2/n_tot*36 & response_no != obs_plot_location) %>%
  summarize(n_tot = n_tot, n = n())

intercept <- mean(turk6df$n/turk6df$n_tot*36)

exdf <- filter(studies_sum, pic_name == "file147f93f77aae9.png") %>%
  filter(n != 0) %>%
  rename(.sample = response_no)

exdf_targetcount <- sum(filter(exdf, .sample == obs_plot_location)$n)
exdf_nullcount <- sum(filter(exdf, .sample != obs_plot_location)$n)
total_n <- exdf_targetcount+exdf_nullcount
old_vispval <- vis_p_value_orig(exdf_targetcount, total_n)
new_vispval <- vis_p_value(exdf_targetcount, total_n, alpha = .07)
@
\svp{Using the mixture model proposed here, computed visual p-values will be more moderate than those computed using the approach proposed in \citet{majumder2013validation}.}
\svp{As an example, a lineup from a past experiment is provided in \autoref{fig:example-plot}. This lineup shows a plot which is somewhat ambiguous: the data plot, in panel 5+3, was selected most frequently by participants (14 times), but in total, null plots were selected more frequently than the target plot (22 times).}
Under the model proposed in \citet{majumder2013validation}, this plot would produce a visual $p$-value \hh{on the order} of $10^-9$, %\Sexpr{old_vispval}
which \hh{seems} extremely small given that there were more null plot selections than data plot selections.

<<example-plot, dependson = "example-setup", echo = F, fig.width = 5, fig.height = 5, fig.align="center", out.width = ".8\\textwidth", fig.cap = "A lineup designed to test the utility of boxplots for detecting distributional differences. Selection counts are provided in light grey on top of each panel which was selected at least once. The data panel is highlighted in dark grey (panel 8).">>=
ggplot(exdat, aes(x = group, y = vals, fill = factor(group))) + 
  geom_boxplot() + 
  facet_wrap(~.sample) + 
  theme_bw() + 
  theme(axis.text = element_blank(), axis.title = element_blank(), axis.ticks = element_blank()) + 
  scale_fill_discrete(guide = "none") +
#  geom_rect(aes(xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf), fill="white", alpha = 0.003) +
  annotate("rect", xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf, fill="white", alpha = 0.5) +
  geom_text(aes(x = 1.5, y = 0.830, label = n), nudge_x = 0, nudge_y = 0, hjust = .5, vjust = .5, inherit.aes = F, size = 20, data = exdf, color = "grey70", alpha =0.8) +
  geom_rect(aes(xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf), fill="black", alpha = 0.5, inherit.aes=FALSE, data = exdf %>% filter(.sample==8)) +
  geom_text(aes(x = 1.5, y = 0.830, label = n), nudge_x = 0, nudge_y = 0, hjust = .5, vjust = .5, inherit.aes=FALSE,
  data = exdf %>% filter(.sample==8),
  size = 20, color = "grey90", alpha =0.7)

# ggplot(exdat, aes(x = group, y = vals, fill = factor(group))) +
#   geom_text(aes(x = Inf, y = -Inf, label = n), nudge_x = -1, nudge_y = 1, hjust = 1.2, vjust = -0.2, inherit.aes = F, size = 10, data = exdf, color = "grey80") +
#   geom_boxplot() +
#   facet_wrap(~.sample) +
#   theme_bw() +
#   theme(axis.text = element_blank(), axis.title = element_blank(), axis.ticks = element_blank()) +
#   scale_fill_discrete(guide = "none")


@
\svp{Under the Dirichlet-Multinomial model in \autoref{eqn:full-model-specification}, the first step is to assess the expected number of null panels which  attract attention.}
\hh{Six of 19 null plots were selected at least once. The corresponding simulation in \autoref{fig:example-alpha-curve} suggest a value of $\alpha$ between 0.1 and 0.25.}

<<example-alpha-curve, fig.cap = "Number of expected panels with more than one selection in the 22 null plot selections  for the lineup shown in \\autoref{fig:example-plot}.", fig.width = 8, fig.height = 4, out.width = "\\textwidth">>=

interest_threshold <- 0
alphas <- 10^(seq(-3.5, 2, by = .01)) # seq(0.001, 0.5, by = .001)

# Get theoretical function
model_df <- tibble(alpha = alphas,
                   n_sel_plots = alphas %>%
                     map_dbl(number_panels, K = 22, m = 19, c = interest_threshold)
)

# Get simulated data
prior_pred_mean <- sim_interesting_panels(c = interest_threshold, K = 22, m = 19, alphas = alphas) %>%
  arrange(alpha) %>%
  mutate(label = sprintf("alpha == %f", alpha) %>%
           factor(levels = sprintf("alpha == %f", alphas), ordered = T))

# Get possible breakpoints for alphas and panels
panel_sel_breaks <- c(5, 7)
possible_breakpoints <- model_df %>%
  filter(round(n_sel_plots - floor(n_sel_plots), 1) == .5 |
           round(n_sel_plots - floor(n_sel_plots), 1) == 0) %>%
  mutate(tmp = floor(n_sel_plots*2)/2, dist = abs(n_sel_plots - tmp)) %>%
  group_by(tmp) %>%
  filter(dist == min(dist)) %>%
  filter(tmp %in% panel_sel_breaks) %>%
  ungroup() %>%
  mutate(band = floor(.5 + row_number()/2))

panel_selected <- 6
selected_breakpoints <- model_df %>%
  filter(round(n_sel_plots - floor(n_sel_plots), 1) == .5 |
           round(n_sel_plots - floor(n_sel_plots), 1) == 0) %>%
  mutate(tmp = floor(n_sel_plots*2)/2, dist = abs(n_sel_plots - tmp)) %>%
  group_by(tmp) %>%
  filter(dist == min(dist)) %>%
  filter(tmp %in% panel_selected) %>%
  ungroup() %>%
  mutate(band = floor(.5 + row_number()/2))



# polygons for the grey-and-white bands
bands <- possible_breakpoints %>%
  rename(x = alpha, y = n_sel_plots) %>%
  nest(data = -band) %>%
  mutate(polys = purrr::map(data, lag_polys)) %>%
  unnest(polys)

# minor break points
mb <- crossing(x = c(2.5, 5, 7.5), y = 10^(seq(-4, 5))) %>%
  mutate(z = x*y) %>%
  `[`("z") %>%
  unlist() %>%
  as.numeric

# text labels for polygon bands
band_label_pos <- panel_sel_breaks + 1 # this is a good default but may need customizing
band_labels <- tibble(
  y = band_label_pos,
  x = min(alphas),
  label = c("5-7 (26%-37%)\ninteresting panels", "")
)

# Finally, the actual plot
ggplot() +
  geom_polygon(aes(x = x, y = y, group = interaction(type, band)), data = bands, fill = "grey", alpha = 0.5) +
  geom_point(aes(x = alpha, y = n_interesting),data = prior_pred_mean, alpha = .05) +
  geom_line(aes(x = alpha, y = n_sel_plots), data = model_df, color = "blue", size = 1) +
  scale_x_log10(name = expression(alpha), breaks = c(0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000),
                minor_breaks = mb,
                labels = 10^(seq(-3, 4))) +
  geom_text(aes(x = x, y = y, label = label), data = band_labels, hjust = 0, color = "grey30", size = 3) +
  coord_cartesian(xlim = range(alphas)) +
  scale_y_continuous(name = paste0("Number of panels with at least ",
                                   interest_threshold+1, " selection"),
                     breaks = 1:100) +
  annotate("segment", x=0.000001, xend=selected_breakpoints$alpha,
               y=6, yend=6,
               colour="grey50") +
  annotate("segment", x=selected_breakpoints$alpha,
           xend=selected_breakpoints$alpha,
               y=-Inf, yend=6,
               colour="grey50")

@

\svp{
%We divide the range of the expectation into bands covering 2-3 panels: 2-4, 5-7, 7-9, and 10+ panels. Our lineups tend to have between 6 and 7 null plots selected, so a reasonable choice for $\alpha$ is $0.25$, which is in the middle of the 5-7 band in \autoref{fig:example-alpha-curve}.
The visual p-value for the lineup in \autoref{fig:example-plot}(a), under the Beta-Binomial mixture model, is \Sexpr{new_vispval}; while this is still significant at the 0.05 level, it is not nearly as small as the p-value computed under the Binomial model.
When we consider the actual results of the experimental evaluation of \autoref{fig:example-plot}(a), the p-value computed using the mixture model is much more plausible: the data plot is clearly the most favored of all of the panels in the lineup, but it is not overwhelmingly significant; at least one other panel is almost as popular, and overall, null panels were still selected more frequently than the data panel.
This suggests that p-values generated using the Beta-Binomial mixture model are better calibrated than those generated by the Binomial model: by accounting for the underlying perceptual processes, we can produce a more accurate method for conducting visual inference.
}

\section{Discussion}

\svp{Multinomial-Dirichlet model produces more plausible p-values}

\svp{Visual estimation of $\alpha$ via simulation allows us to use the multinomial-dirichlet model to obtain p-values which are reasonable and which account for the difficulty of the lineup and null plot generation method}

\svp{Visual estimation of $\alpha$ also allows us to screen out lineup generation methods which are problematic: if a null plot generation method produces 1 interesting plot out of a 20-plot Rorschach lineup, it is functionally impossible to distinguish a data plot which has a large signal from a null plot which also has a large signal. Extremely small $\alpha$ values, then, serve as a signal that the null plot generation method is not visually appropriate because it sporadically (not consistently) generates visual features that are likely to catch the attention of participants (possibly for the wrong reasons).}



% \nocite{*}% Show all bib entries - both cited and uncited; comment this line to view only cited bib entries;
\bibliography{references}%


\section*{Author Biography}

\begin{biography}{%\includegraphics[width=60pt,height=70pt,draft]{empty}
}{\textbf{Author Name.} This is sample author biography text this is sample author biography text this is sample author biography text this is sample author biography text this is sample author biography text this is sample author biography text this is sample author biography text this is sample author biography text this is sample author biography text this is sample author biography text this is sample author biography text this is sample author biography text this is sample author biography text this is sample author biography text this is sample author biography text this is sample author biography text this is sample author biography text this is sample author biography text this is sample author biography text this is sample author biography text this is sample author biography text.}
\end{biography}

\begin{appendix}
\section{Visual $p$-value distribution}\label{app:pvalue}
Assume, we have a lineup of size $m$ with $K$ evaluations resulting in $c_t$ target plot evaluations. We defined the Beta-Binomial model in \autoref{eqn:marginal-model-specification} leading to densities given as:

\begin{align*}
f(\theta \mid \alpha) & = \svp{\frac{1}{B\left(\alpha, (m-1)\alpha\right)}}\cdot \theta^{\alpha - 1}(1-\theta)^{(m-1)\alpha - 1}\\
\\
P(C = c_t  \mid K, \theta) & =  \binom{K}{c_t}\theta^{c_t}(1-\theta)^{K-c_t}
\end{align*}
% By Bayes Theorem, if $A_1 = C + \alpha$ and $A_2 = K - C + (m-1)\alpha$,
% \begin{align*}
% f(\theta|C, K, \alpha) &= \frac{f(\theta|\alpha) P(C | \theta)}{P(C = c)}\\
% &= \frac{B\left(\alpha, (m-1)\alpha\right)}{P(C=c)} \theta^{\alpha - 1}(1-\theta)^{(m-1)\alpha - 1}\cdot \binom{K}{C}\theta^C(1-\theta)^{K-C}\\
% &= \frac{1}{P(C=c)} B\left(\alpha, (m-1)\alpha\right) \binom{K}{C} \theta^{A_1 - 1}(1-\theta)^{A_2 - 1}\\
% \end{align*}
%
% As $f(\theta|C, K, \alpha)$ is a probability distribution, it integrates to 1. So we can infer that
% \begin{align*}
% P(C=c) &= \int B\left(\alpha, (m-1)\alpha\right) \binom{K}{C} \theta^{A_1 - 1}(1-\theta)^{A_2 - 1} d\theta\\
% & = B\left(\alpha, (m-1)\alpha\right) \binom{K}{C} \int \theta^{A_1 - 1}(1-\theta)^{X_2 - 1} d\theta\\
% & = B\left(\alpha, (m-1)\alpha\right) \binom{K}{C} \frac{B(A_1, A_2)}{B(A_1, A_2)} \int \theta^{A_1 - 1}(1-\theta)^{A_2 - 1} d\theta\\
% & =   \frac{B\left(\alpha, (m-1)\alpha\right) \binom{K}{C}}{B(A_1, A_2)\alpha)} \int B(A_1, A_2) \theta^{A_1 - 1}(1-\theta)^{A_2 - 1} d\theta\\
% & =  \frac{B\left(\alpha, (m-1)\alpha\right) \binom{K}{C} }{B\left(C+\alpha, K-C+(m-1)\alpha\right)} \\
% \end{align*}

\hh{We are interested in the probability of observing at least $c_t$ picks of the target plot assuming that the target plot is not inconsistent with the null plots generated from the null model, i.e. we are interested in the (unconditional) distribution of counts $C$. We get there by integrating over the rate parameter $\theta$.
From the theorem of total probability we know that }
\begin{eqnarray*}
P(C = c) &=& \int_0^1 P(C = c \mid \theta) f(\theta) d\theta
\end{eqnarray*}

\hh{Now we use that $C \mid \theta \sim$ Binom$_{\theta, K}$ and $\theta \sim$ Beta$_{\alpha, (m-1)\alpha}$:}

\begin{eqnarray*}
P(C = c) &=&  \int_0^1 {K \choose c} \theta^c (1-\theta)^{K - c} \cdot
\frac{1}{B(\alpha, (m-1)\alpha)} \theta^{\alpha - 1}(1-\theta)^{(m-1)\alpha-1} d\theta = \\
&=& {K \choose c} \frac{1}{B(\alpha, (m-1)\alpha)} \underbrace{\int_0^1
 \theta^{c + \alpha - 1}(1-\theta)^{K-c + (m-1)\alpha-1} d\theta}_{\text{Beta function}} =\\
 &=& {K \choose c} \frac{B(c+\alpha, K-c + (m-1)\alpha)}{B(\alpha, (m-1)\alpha)}.
\end{eqnarray*}


Thus, the visual p-value for a lineup with $c_t$ target selections out of $K$ evaluations is
\begin{align}
P(C \geq c_t) & =  \frac{1}{B(\alpha, (m-1)\alpha) } \sum_{x=c_t}^K \binom{K}{x} B(x+\alpha, K-x+(m-1)\alpha).
\end{align}
A similar derivation holds in the full Dirichlet-Multinomial model.

\section{Expected number of panels picked}\label{app:expected}
Define $C = (C_1, ..., C_m) \sim \text{Mult}_{\theta, K}$ to be a (simulated) lineup that is evaluated $K$ times, and $\theta = (\theta_1, ..., \theta_m) \sim \text{Dir}_\alpha = (\alpha, ..., \alpha)$ with $\sum_i \theta_i = 1$.

With indicator function $I$, defined as 1 for true statements and 0 for false statements, we define:

\[
Z_c(\alpha) = \sum_{i=1}^{m} I(C_i > c),
\]
where $Z_c$ is the number of panels in a lineup that were picked more than $c$ times. We express this random variable as a function in $\alpha$ - the dependency becomes clear, once we look at the expected value of $Z_c$:

\[
E[Z_c(\alpha)] = \sum_{i=1}^m E\left[ I(C_i > c) \right] =
\sum_{i=1}^m P(C_i > c).
\]

The probabilities $P(C_i > c)$ are derived in the previous section as marginal DBeta-binomials:
\begin{equation}\label{eqn:differentPanels}
E[Z_c(\alpha)] = \frac{m}{ B(\alpha, (m-1)\alpha)} \cdot \sum_{x=c+1}^K \binom{K}{x} B(x+\alpha, K-x+(m-1)\alpha).
\end{equation}

\section{Subvectors of Dirichlet distributions}\label{neutrality}

Let $\bm\theta = (\theta_1, ... \theta_m)$ with $\bm\theta \sim $Dir$(\alpha)$ for some real-valued $\alpha > 0$. 
The Dirichlet distribution is neutral with respect to all possible partitions of the corresponding index set \citep{Connor:1969bt, doksum:74, Sakowicz:2014hi}.
This means that  $\theta_m$ is independent of the (normalized) random variable $\bm\theta^{-m} := (\frac{\theta_1}{1-\theta_m}, ..., \frac{\theta_{m-1}}{{1-\theta_m}})$. 
Further, this implies that the conditional distribution $\bm\theta^{-m} \mid \theta_m \sim $ Dir$(\alpha)$.

In the context of lineups this means that given the same null model generation we can assume for the probabilities to select a panel from a Rorschach lineup and the probabilities to select a panel corresponding to a null plot from a lineup Dirichlet distributions with the same parameter $\alpha > 0$. 
\end{appendix}
\end{document}
